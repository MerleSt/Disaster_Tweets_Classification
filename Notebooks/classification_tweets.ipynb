{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:40:54.338197Z",
     "start_time": "2023-11-17T09:40:49.436172Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/Users/merlesteffen/Documents/GitHub/Disaster_Tweets_Classification/Data/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:40:54.345892Z",
     "start_time": "2023-11-17T09:40:54.339055Z"
    }
   },
   "id": "310a50713235871e"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/merlesteffen/Documents/GitHub/Disaster_Tweets_Classification/Data/train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:40:54.357651Z",
     "start_time": "2023-11-17T09:40:54.346556Z"
    }
   },
   "id": "83884ce4e6f265c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split Dataset Test/Train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53ecc0618c75a0c"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(train_df, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:40:54.363728Z",
     "start_time": "2023-11-17T09:40:54.358870Z"
    }
   },
   "id": "48d3d2d23c191815"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BERT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c42b1a625779815d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ede079388887ddd6"
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:40:55.039527Z",
     "start_time": "2023-11-17T09:40:54.791429Z"
    }
   },
   "id": "c50f75b8bbef62ff"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "train_encodings = tokenizer(df_train['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(df_test['text'].tolist(), truncation=True, padding=True, max_length=512)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:00:43.924563Z",
     "start_time": "2023-11-17T09:00:42.823344Z"
    }
   },
   "id": "1dd9a0d3c31411dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4ed51648f9cad57"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:00:43.928866Z",
     "start_time": "2023-11-17T09:00:43.925542Z"
    }
   },
   "id": "714b34d6c1c7dd83"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = TextDataset(train_encodings, df_train['target'].tolist())\n",
    "test_dataset = TextDataset(test_encodings, df_test['target'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:00:43.929370Z",
     "start_time": "2023-11-17T09:00:43.927784Z"
    }
   },
   "id": "19991da321fcbe8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-Tuning BERT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "867146d26fbd3ac6"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:00:44.811539Z",
     "start_time": "2023-11-17T09:00:43.929806Z"
    }
   },
   "id": "7fb864a70560640f"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8,   \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',            \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:00:44.823876Z",
     "start_time": "2023-11-17T09:00:44.812205Z"
    }
   },
   "id": "3ee0fd16863de3c0"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/merlesteffen/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/merlesteffen/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_config.py:318: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:00:45.174679Z",
     "start_time": "2023-11-17T09:00:44.824351Z"
    }
   },
   "id": "854c608590fc00cf"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/2286 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=2286, training_loss=0.39576279981451296, metrics={'train_runtime': 472.9555, 'train_samples_per_second': 38.629, 'train_steps_per_second': 4.833, 'total_flos': 788654832890400.0, 'train_loss': 0.39576279981451296, 'epoch': 3.0})"
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:08:38.256952Z",
     "start_time": "2023-11-17T09:00:45.292338Z"
    }
   },
   "id": "6ab94dcb49a29854"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make Predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "365aa8f1329761b9"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='191' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/191 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to labels\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:08:45.098650Z",
     "start_time": "2023-11-17T09:08:38.257769Z"
    }
   },
   "id": "248281cd7aa0a39b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65e055cbfe911a9d"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8200919238345371\n"
     ]
    }
   ],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(df_test['target'], pred_labels)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:08:45.103892Z",
     "start_time": "2023-11-17T09:08:45.101074Z"
    }
   },
   "id": "2853e6f2664b9f9b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train on entire Dataset (Train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cd2c7a001f8b376"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "171f15659fac4c91"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "# Tokenize the training text\n",
    "train_encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Tokenize the test text\n",
    "test_encodings = tokenizer(test_df['text'].tolist(), truncation=True, padding=True, max_length=512)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:41:16.961338Z",
     "start_time": "2023-11-17T09:41:15.455505Z"
    }
   },
   "id": "7090aa748c63eba4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Tensors and Create Datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bfaa26ad8a01202"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:41:19.462630Z",
     "start_time": "2023-11-17T09:41:19.453084Z"
    }
   },
   "id": "158f333c832d7181"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_data = TextDataset(train_encodings, train_df['target'].tolist())\n",
    "test_data = TextDataset(test_encodings)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:42:05.169241Z",
     "start_time": "2023-11-17T09:42:05.162683Z"
    }
   },
   "id": "5d07806400bdde14"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create DataLoader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36ef5e637566c9bd"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 8\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:42:06.172917Z",
     "start_time": "2023-11-17T09:42:06.170236Z"
    }
   },
   "id": "e10c470b04d68de5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb80186bc35ebfcb"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/merlesteffen/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/merlesteffen/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_config.py:318: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Create a Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:42:09.045676Z",
     "start_time": "2023-11-17T09:42:07.880076Z"
    }
   },
   "id": "cb005654543094ca"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2856' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/2856 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=2856, training_loss=0.3902771573106782, metrics={'train_runtime': 587.1036, 'train_samples_per_second': 38.901, 'train_steps_per_second': 4.865, 'total_flos': 985883291099280.0, 'train_loss': 0.3902771573106782, 'epoch': 3.0})"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:51:56.528426Z",
     "start_time": "2023-11-17T09:42:09.412395Z"
    }
   },
   "id": "3ae51431dfa648dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make Predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7201b513b8a1a12"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='1' max='408' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  1/408 : < :]\n    </div>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions\n",
    "predictions = trainer.predict(test_data)\n",
    "\n",
    "# Convert predictions to labels\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Assuming you want to attach these predictions to your test_df\n",
    "test_df['predicted_label'] = pred_labels"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:52:11.313999Z",
     "start_time": "2023-11-17T09:51:56.527064Z"
    }
   },
   "id": "408c91218020b262"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Submission File"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bf10c00257e2013"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "# Create the submission DataFrame\n",
    "submission_df = test_df[['id', 'predicted_label']]\n",
    "\n",
    "# Rename 'predicted_label' to 'target'\n",
    "submission_df = submission_df.rename(columns={'predicted_label': 'target'})\n",
    "\n",
    "# Save to CSV file\n",
    "submission_df.to_csv('/Users/merlesteffen/Documents/GitHub/Disaster_Tweets_Classification/Data/submissions/submissions.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:52:11.326743Z",
     "start_time": "2023-11-17T09:52:11.313674Z"
    }
   },
   "id": "82f5b7977e24a0d"
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "         id  target\n0         0       1\n1         2       1\n2         3       1\n3         9       1\n4        11       1\n...     ...     ...\n3258  10861       1\n3259  10865       1\n3260  10868       1\n3261  10874       1\n3262  10875       1\n\n[3263 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:57:25.415691Z",
     "start_time": "2023-11-17T09:57:25.409954Z"
    }
   },
   "id": "5ce3a6f43c207ad9"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "data": {
      "text/plain": "         id  target\n0         0       1\n1         2       1\n2         3       1\n3         9       1\n4        11       1\n...     ...     ...\n3258  10861       1\n3259  10865       1\n3260  10868       1\n3261  10874       1\n3262  10875       1\n\n[3263 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>id</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>9</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>11</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>3258</th>\n      <td>10861</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3259</th>\n      <td>10865</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3260</th>\n      <td>10868</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3261</th>\n      <td>10874</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3262</th>\n      <td>10875</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>3263 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T09:59:07.475025Z",
     "start_time": "2023-11-17T09:59:07.472742Z"
    }
   },
   "id": "bdac0ea280c00055"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
