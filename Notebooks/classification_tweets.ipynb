{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "start_time": "2023-11-17T08:25:20.569963Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "from transformers import BertForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "test_df = pd.read_csv('/Users/merlesteffen/Documents/GitHub/Disaster_Tweets_Classification/Data/test.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:12:30.869944Z",
     "start_time": "2023-11-17T08:12:30.858631Z"
    }
   },
   "id": "310a50713235871e"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('/Users/merlesteffen/Documents/GitHub/Disaster_Tweets_Classification/Data/train.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:12:31.977842Z",
     "start_time": "2023-11-17T08:12:31.954182Z"
    }
   },
   "id": "83884ce4e6f265c6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Split Dataset Test/Train"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "53ecc0618c75a0c"
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "df_train, df_test = train_test_split(train_df, test_size=0.2, random_state=42)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:12:37.786073Z",
     "start_time": "2023-11-17T08:12:37.777218Z"
    }
   },
   "id": "48d3d2d23c191815"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# BERT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c42b1a625779815d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ede079388887ddd6"
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:12:39.183334Z",
     "start_time": "2023-11-17T08:12:38.992329Z"
    }
   },
   "id": "c50f75b8bbef62ff"
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "# Tokenize the text\n",
    "train_encodings = tokenizer(df_train['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(df_test['text'].tolist(), truncation=True, padding=True, max_length=512)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:12:40.985125Z",
     "start_time": "2023-11-17T08:12:39.933114Z"
    }
   },
   "id": "1dd9a0d3c31411dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Creating Datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e4ed51648f9cad57"
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "class TextDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:17:05.080624Z",
     "start_time": "2023-11-17T08:17:05.073772Z"
    }
   },
   "id": "714b34d6c1c7dd83"
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "# Create datasets\n",
    "train_dataset = TextDataset(train_encodings, df_train['target'].tolist())\n",
    "test_dataset = TextDataset(test_encodings, df_test['target'].tolist())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:17:13.200627Z",
     "start_time": "2023-11-17T08:17:13.195362Z"
    }
   },
   "id": "19991da321fcbe8f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fine-Tuning BERT"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "867146d26fbd3ac6"
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT model\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:17:15.655490Z",
     "start_time": "2023-11-17T08:17:14.844837Z"
    }
   },
   "id": "7fb864a70560640f"
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',          \n",
    "    num_train_epochs=3,              \n",
    "    per_device_train_batch_size=8,  \n",
    "    per_device_eval_batch_size=8,   \n",
    "    warmup_steps=500,                \n",
    "    weight_decay=0.01,               \n",
    "    logging_dir='./logs',            \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:17:15.913546Z",
     "start_time": "2023-11-17T08:17:15.891578Z"
    }
   },
   "id": "3ee0fd16863de3c0"
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/merlesteffen/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_fields.py:149: UserWarning: Field \"model_server_url\" has conflict with protected namespace \"model_\".\n",
      "\n",
      "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
      "  warnings.warn(\n",
      "/Users/merlesteffen/anaconda3/lib/python3.11/site-packages/pydantic/_internal/_config.py:318: UserWarning: Valid config keys have changed in V2:\n",
      "* 'schema_extra' has been renamed to 'json_schema_extra'\n",
      "  warnings.warn(message, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "# Create a Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,                         \n",
    "    args=training_args,                  \n",
    "    train_dataset=train_dataset,         \n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:17:17.126885Z",
     "start_time": "2023-11-17T08:17:16.679860Z"
    }
   },
   "id": "854c608590fc00cf"
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n    <div>\n      \n      <progress value='2' max='2286' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [   2/2286 : < :, Epoch 0.00/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "TrainOutput(global_step=2286, training_loss=0.38680574712477955, metrics={'train_runtime': 475.585, 'train_samples_per_second': 38.416, 'train_steps_per_second': 4.807, 'total_flos': 788654832890400.0, 'train_loss': 0.38680574712477955, 'epoch': 3.0})"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:25:13.108727Z",
     "start_time": "2023-11-17T08:17:17.510719Z"
    }
   },
   "id": "6ab94dcb49a29854"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Make Predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "365aa8f1329761b9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = trainer.predict(test_dataset)\n",
    "\n",
    "# Convert predictions to labels\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T08:25:20.570656Z"
    }
   },
   "id": "248281cd7aa0a39b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Evaluate Model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "65e055cbfe911a9d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(df_test['target'], pred_labels)\n",
    "print(f\"Accuracy: {accuracy}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T08:25:20.571258Z"
    }
   },
   "id": "2853e6f2664b9f9b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Calculate F1 score\n",
    "f1 = f1_score(df_test['target_column'], pred_labels)\n",
    "print(f\"F1 Score: {f1}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-11-17T08:25:20.571948Z"
    }
   },
   "id": "35e0f3e020c2da92"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Train on entire Dataset (Train)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6cd2c7a001f8b376"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Tokenization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "171f15659fac4c91"
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "outputs": [],
   "source": [
    "# Tokenize the training text\n",
    "train_encodings = tokenizer(train_df['text'].tolist(), truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Tokenize the test text\n",
    "test_encodings = tokenizer(test_df['text'].tolist(), truncation=True, padding=True, max_length=512)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-11-17T08:26:35.361740Z",
     "start_time": "2023-11-17T08:26:33.929494Z"
    }
   },
   "id": "7090aa748c63eba4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Convert to Tensors and Create Datasets"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3bfaa26ad8a01202"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Convert training data to tensors\n",
    "train_seq = torch.tensor(train_encodings['input_ids'])\n",
    "train_mask = torch.tensor(train_encodings['attention_mask'])\n",
    "train_y = torch.tensor(train_df['target_column'].tolist())\n",
    "\n",
    "# Convert test data to tensors\n",
    "test_seq = torch.tensor(test_encodings['input_ids'])\n",
    "test_mask = torch.tensor(test_encodings['attention_mask'])\n",
    "\n",
    "# Create TensorDatasets for train and test\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "test_data = TensorDataset(test_seq, test_mask)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5d07806400bdde14"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Create DataLoader"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "36ef5e637566c9bd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Define batch size\n",
    "batch_size = 8\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dataloader = DataLoader(train_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e10c470b04d68de5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fb80186bc35ebfcb"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Load the BERT model for sequence classification\n",
    "model = BertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Define training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir='./results',\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    logging_dir='./logs',\n",
    ")\n",
    "\n",
    "# Create a Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    ")"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cb005654543094ca"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Train the model\n",
    "trainer.train()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ae51431dfa648dd"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Make Predictions"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a7201b513b8a1a12"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = trainer.predict(test_data)\n",
    "\n",
    "# Convert predictions to labels\n",
    "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
    "\n",
    "# Assuming you want to attach these predictions to your test_df\n",
    "test_df['predicted_label'] = pred_labels"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "408c91218020b262"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Create Submission File"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9bf10c00257e2013"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Create the submission DataFrame\n",
    "submission_df = test_df[['id', 'predicted_label']]\n",
    "\n",
    "# Rename 'predicted_label' to 'target'\n",
    "submission_df = submission_df.rename(columns={'predicted_label': 'target'})\n",
    "\n",
    "# Save to CSV file\n",
    "submission_df.to_csv('/Users/merlesteffen/Documents/GitHub/Disaster_Tweets_Classification/Data/submissions/submission.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "82f5b7977e24a0d"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
